{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# from utils import Utils\n",
    "import nibabel as nib\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_landmarks(image_path, landmarks_path, slice_index):\n",
    "    \"\"\"\n",
    "    Visualize landmarks on a specific slice of a NIfTI image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the NIfTI image file.\n",
    "        landmarks_path (str): Path to the landmarks text file.\n",
    "        slice_index (int): The slice index to visualize.\n",
    "    \"\"\"\n",
    "    # Load the NIfTI image\n",
    "    img = nib.load(image_path)\n",
    "    image = img.get_fdata()\n",
    "    \n",
    "    # Load the landmarks and ensure they are integers\n",
    "    landmarks = np.loadtxt(landmarks_path).astype(int)\n",
    "    \n",
    "    # Plot the image and overlay landmarks\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image[:, :, slice_index], cmap='gray')\n",
    "    for x, y, z in landmarks:\n",
    "        if z == slice_index: \n",
    "            plt.scatter(x, y, c='red', s=20, label='Landmark')\n",
    "    plt.title(f'Slice {slice_index} with Landmarks')\n",
    "    plt.axis('off')\n",
    "    plt.legend(['Landmark'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def parse_transformed_landmarks(file_path, export=False, export_dir=None):\n",
    "    \"\"\"\n",
    "    Parse transformed landmarks from outputpoints.txt.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the outputpoints.txt file.\n",
    "        export (bool): If True, save the points serially to a text file.\n",
    "        export_dir (str): Directory to save the exported file. \n",
    "                          If None, saves in the same directory as file_path.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of parsed landmark points.\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if \"OutputPoint\" in line:\n",
    "                # Extract coordinates from OutputPoint\n",
    "                coords = line.split(\"OutputPoint = [\")[1].split(\"]\")[0]\n",
    "                points.append(list(map(float, coords.split())))\n",
    "\n",
    "    points_array = np.array(points)\n",
    "\n",
    "    if export:\n",
    "        # Extract the basename of the input file for naming\n",
    "        basename = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        \n",
    "        # Construct a descriptive file name\n",
    "        export_file_name = f\"{basename}_transformed_points.txt\"\n",
    "        \n",
    "        # Define the export directory\n",
    "        if export_dir is None:\n",
    "            export_dir = os.path.dirname(file_path)\n",
    "        \n",
    "        # Ensure the export directory exists\n",
    "        if not os.path.exists(export_dir):\n",
    "            os.makedirs(export_dir)\n",
    "\n",
    "        # Construct the full path for the export file\n",
    "        export_file = os.path.join(export_dir, export_file_name)\n",
    "\n",
    "        # Save the points serially to the export file\n",
    "        with open(export_file, 'w') as out_file:\n",
    "            for idx, point in enumerate(points_array, start=1):\n",
    "                out_file.write(f\"{idx}: {point[0]:.6f}, {point[1]:.6f}, {point[2]:.6f}\\n\")\n",
    "\n",
    "    return points_array\n",
    "\n",
    "def parse_original_landmarks(file_path):\n",
    "    \"\"\"Parse original landmarks from text files.\"\"\"\n",
    "    points = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.strip():\n",
    "                # Extract coordinates\n",
    "                coords = list(map(float, line.strip().split()))\n",
    "                points.append(coords)\n",
    "                points_np = np.array(points)\n",
    "                points_np[:, 2] *= -1\n",
    "    return points_np\n",
    "\n",
    "def calculate_tre_mm(transformed_landmarks, original_landmarks, voxel_spacing):\n",
    "    \"\"\"\n",
    "    Calculate Target Registration Error (TRE) in mm space.\n",
    "\n",
    "    Args:\n",
    "        transformed_landmarks (numpy.ndarray): Transformed landmarks (Nx3).\n",
    "        original_landmarks (numpy.ndarray): Original landmarks (Nx3).\n",
    "        voxel_spacing (tuple): Spacing of voxels in mm (x_spacing, y_spacing, z_spacing).\n",
    "\n",
    "    Returns:\n",
    "        # list: TRE for each point.\n",
    "        float: Mean TRE.\n",
    "    \"\"\"\n",
    "    # Apply voxel spacing to original landmarks\n",
    "    scaled_original_landmarks = original_landmarks * np.array(voxel_spacing)\n",
    "    # scaled_original_landmarks[:, 2] *= -1  # Invert z-axis\n",
    "    scaled_transformed_landmarks = transformed_landmarks \n",
    "    # Calculate the Euclidean distances\n",
    "    # distances = np.linalg.norm(scaled_transformed_landmarks - scaled_original_landmarks, axis=1)\n",
    "    distances = np.sqrt(np.sum((scaled_original_landmarks - scaled_transformed_landmarks)**2 , axis=1))\n",
    "    # Compute mean TRE\n",
    "    mean_tre = np.mean(distances)\n",
    "    # Compute standard deviation of TRE\n",
    "    std_tre = np.std(distances)\n",
    "    return mean_tre, std_tre\n",
    "\n",
    "def register_and_transform_images(\n",
    "    fixed_image_path, moving_image_path, param_file_paths, output_dir, point_set_path):\n",
    "    \"\"\"\n",
    "    Register images and apply transformations using SimpleITK.\n",
    "\n",
    "    Parameters:\n",
    "        fixed_image_path (str): Path to the fixed image.\n",
    "        moving_image_path (str): Path to the moving image.\n",
    "        param_file_paths (str or list of str): Path(s) to the parameter file(s). Can be a single file or a list of files.\n",
    "        output_dir (str): Path to the output directory.\n",
    "        point_set_path (str): Path to the point set file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Paths to the registered image file and transformed points file.\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    fixed_image = sitk.ReadImage(fixed_image_path)\n",
    "    moving_image = sitk.ReadImage(moving_image_path)\n",
    "\n",
    "    # Extract the basename of the moving image for file naming\n",
    "    basename = os.path.basename(moving_image_path).split(\".\")[0]\n",
    "\n",
    "    # Set up ElastixImageFilter for registration\n",
    "    elastixImageFilter = sitk.ElastixImageFilter()\n",
    "    elastixImageFilter.SetFixedImage(fixed_image)\n",
    "    elastixImageFilter.SetMovingImage(moving_image)\n",
    "\n",
    "    # Ensure param_file_paths is a list (to handle both single and multiple files)\n",
    "    if isinstance(param_file_paths, str):\n",
    "        param_file_paths = [param_file_paths]\n",
    "\n",
    "    # Load the parameter files (can be single or multiple)\n",
    "    parametervectormap = sitk.VectorOfParameterMap()\n",
    "    for param_file_path in param_file_paths:\n",
    "        paramater_file = sitk.ReadParameterFile(param_file_path)\n",
    "        parametervectormap.append(paramater_file)\n",
    "    \n",
    "    elastixImageFilter.SetParameterMap(parametervectormap)\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Set the output directory and execute the transformation\n",
    "    elastixImageFilter.SetOutputDirectory(output_dir)\n",
    "    elastixImageFilter.Execute()\n",
    "\n",
    "    # Save the registered image with a descriptive name\n",
    "    registered_image_path = os.path.join(output_dir, f\"{basename}_reg.nii.gz\")\n",
    "    sitk.WriteImage(elastixImageFilter.GetResultImage(), registered_image_path)\n",
    "\n",
    "    # Set up TransformixImageFilter for point transformation\n",
    "    transform_param_map = elastixImageFilter.GetTransformParameterMap()\n",
    "    transformixImageFilter = sitk.TransformixImageFilter()\n",
    "    transformixImageFilter.SetTransformParameterMap(transform_param_map)\n",
    "    transformixImageFilter.SetFixedPointSetFileName(point_set_path)\n",
    "    transformixImageFilter.SetMovingImage(moving_image)  # Needed to infer dimensionality\n",
    "    transformixImageFilter.SetOutputDirectory(output_dir)\n",
    "    transformixImageFilter.Execute()\n",
    "\n",
    "    # Save the transformed points file with a descriptive name\n",
    "    transformed_points_file = os.path.join(output_dir, f\"{basename}_transform.txt\")\n",
    "\n",
    "    # Rename the output points file to the new descriptive name\n",
    "    original_points_file = os.path.join(output_dir, \"outputpoints.txt\")\n",
    "    \n",
    "    # Check if the target file exists and remove it\n",
    "    if os.path.exists(transformed_points_file):\n",
    "        os.remove(transformed_points_file)\n",
    "    \n",
    "    # Rename the file\n",
    "    os.rename(original_points_file, transformed_points_file)\n",
    "\n",
    "    return transformed_points_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: copd1\n",
      "Mean TRE: 8.11096513828353\n",
      "Std TRE: 5.5697786496343245\n",
      "Directory: copd2\n",
      "Mean TRE: 14.466816747457909\n",
      "Std TRE: 7.070247044430497\n",
      "Directory: copd3\n",
      "Mean TRE: 4.527093003794221\n",
      "Std TRE: 2.9259920762592815\n",
      "Directory: copd4\n",
      "Mean TRE: 7.4394839250088065\n",
      "Std TRE: 3.720076053609129\n",
      "Overall Mean TRE: 7.4394839250088065\n",
      "Overall Std TRE: 3.720076053609129\n"
     ]
    }
   ],
   "source": [
    "# Base directory and parameter file path\n",
    "base_dir = \"dataset\"\n",
    "param_file_path_affine = 'Parameter_Files/Parameters.Par0011.affine.txt'\n",
    "param_file_path = \"Parameter_Files/Parameters.Par0011.bspline1_s.txt\"\n",
    "subdirs = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
    "\n",
    "voxel_spacing_map = {\n",
    "    \"copd1\": (0.62, 0.62, 2.5),\n",
    "    \"copd2\": (0.64, 0.64, 2.5),\n",
    "    \"copd3\": (0.65, 0.65, 2.5),\n",
    "    \"copd4\": (0.59, 0.59, 2.5),\n",
    "    \"copd5\": (0.65, 0.65, 2.5),\n",
    "    \"copd6\": (0.63, 0.63, 2.5),\n",
    "    \"copd7\": (0.62, 0.62, 2.5),\n",
    "    \"copd8\": (0.59, 0.59, 2.5),\n",
    "    \"copd9\": (0.66, 0.66, 2.5),\n",
    "    \"copd10\": (0.74, 0.74, 2.5),\n",
    "}\n",
    "\n",
    "for subdir in subdirs:\n",
    "    overall_mean_tre = []\n",
    "    overall_std_tre = []\n",
    "    input_dir = os.path.join(base_dir, subdir)\n",
    "    fixed_image_path = os.path.join(input_dir, f\"{subdir}_iBHCT.nii.gz\")\n",
    "    moving_image_path = os.path.join(input_dir, f\"{subdir}_eBHCT.nii.gz\")\n",
    "    output_dir = os.path.join(input_dir, \"reg_result\", \"transform_params\")\n",
    "    fixed_point_path = os.path.join(input_dir, f\"{subdir}_300_iBH_xyz_r1.pts\")\n",
    "    landmarks_ex_path = os.path.join(input_dir, f\"{subdir}_300_eBH_xyz_r1.txt\")\n",
    "\n",
    "    voxel_spacing = voxel_spacing_map.get(subdir)\n",
    "    if voxel_spacing is None:\n",
    "        raise ValueError(f\"Voxel spacing for {subdir} not found in voxel_spacing_map.\")\n",
    "\n",
    "    # Register and transform images\n",
    "    transformed_points_file = register_and_transform_images(\n",
    "        fixed_image_path, moving_image_path, [param_file_path_affine, param_file_path], output_dir, fixed_point_path)\n",
    "\n",
    "    # Parse the landmarks\n",
    "    transformed_points = parse_transformed_landmarks(transformed_points_file)\n",
    "    original_points_exhale = parse_original_landmarks(landmarks_ex_path)\n",
    "\n",
    "    # Compute TRE for inhale and exhale landmarks\n",
    "    mean_tre, std_tre = calculate_tre_mm(\n",
    "        transformed_points, original_points_exhale, voxel_spacing=voxel_spacing\n",
    "    )\n",
    "    overall_mean_tre.append(mean_tre)\n",
    "    overall_std_tre.append(std_tre)\n",
    "        \n",
    "    print(f\"Directory: {subdir}\")\n",
    "    print(\"Mean TRE:\", mean_tre)\n",
    "    print(\"Std TRE:\", std_tre)\n",
    "\n",
    "print(\"Overall Mean TRE:\", np.mean(overall_mean_tre))\n",
    "print(\"Overall Std TRE:\", np.mean(overall_std_tre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.061526359758966)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([8.229317027511337, 14.385835106271504, 5.016319842154812, 8.61463346309821])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
